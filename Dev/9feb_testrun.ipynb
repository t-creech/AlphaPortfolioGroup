{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRDS recommends setting up a .pgpass file.\n",
      "Created .pgpass file successfully.\n",
      "You can create this file yourself at any time with the create_pgpass_file() function.\n",
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import logging\n",
    "import wrds\n",
    "\n",
    "# -------------------------\n",
    "# Logging setup\n",
    "# -------------------------\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# -------------------------\n",
    "# WRDS Connection (assumes proper credentials)\n",
    "# -------------------------\n",
    "db = wrds.Connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Dataset: AlphaPortfolioData\n",
    "# -------------------------\n",
    "class AlphaPortfolioData(Dataset):\n",
    "    def __init__(self, start_year=2014, end_year=2020, final_year=2016, lookback=12):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "        - lookback: number of months in historical window (and also forward period length)\n",
    "        - G: parameter used when selecting top assets (here only used for filtering)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lookback = lookback\n",
    "        self.merged, self.final_data = self._load_wrds_data(start_year, end_year, final_year)\n",
    "        self.unique_permnos = sorted(self.final_data['permno'].unique())\n",
    "        self.global_max_assets = len(self.unique_permnos)\n",
    "        self.permno_to_idx = {permno: idx for idx, permno in enumerate(self.unique_permnos)}\n",
    "        self.sequences, self.future_returns, self.masks = self._create_sequences()\n",
    "\n",
    "    def _load_wrds_data(self, start_year, end_year, final_year):\n",
    "        permno_list = []\n",
    "        combined_data = pd.DataFrame()\n",
    "        for year in range(start_year, end_year+1):\n",
    "            start_date = f'{year}-01-01'\n",
    "            end_date = f'{year}-12-31'\n",
    "            crsp_query = f\"\"\"\n",
    "                SELECT a.permno, a.date, a.ret, a.prc, a.shrout, \n",
    "                    a.vol, a.cfacshr, a.altprc, a.retx\n",
    "                FROM crsp.msf AS a\n",
    "                WHERE a.date BETWEEN '{start_date}' AND '{end_date}'\n",
    "                AND a.permno IN (\n",
    "                    SELECT permno FROM crsp.msenames \n",
    "                    WHERE exchcd BETWEEN 1 AND 3  \n",
    "                        AND shrcd IN (10, 11)       \n",
    "                    )\n",
    "                \"\"\"\n",
    "            crsp_data = db.raw_sql(crsp_query)\n",
    "            query_ticker = \"\"\"\n",
    "                SELECT permno, namedt, nameenddt, ticker\n",
    "                FROM crsp.stocknames\n",
    "            \"\"\"\n",
    "            stocknames = db.raw_sql(query_ticker)\n",
    "            crsp_data = crsp_data.merge(stocknames.drop_duplicates(subset=['permno']), on='permno', how='left')\n",
    "            crsp_data = crsp_data.dropna(subset=['ticker'])\n",
    "            crsp_data['mktcap'] = (crsp_data['prc'].abs() * crsp_data['shrout'] * 1000) / 1e6  # In millions\n",
    "            crsp_data['year'] = pd.to_datetime(crsp_data['date']).dt.year\n",
    "            crsp_data = crsp_data.dropna(subset=['mktcap'])\n",
    "            top_50_permnos_by_year = crsp_data.groupby('permno')['mktcap'].agg(['max']).reset_index().sort_values(by='max', ascending=False).head(50)['permno'].unique()\n",
    "            permno_list.extend(top_50_permnos_by_year)\n",
    "            combined_data = pd.concat([combined_data, crsp_data[crsp_data['permno'].isin(permno_list)]], axis=0)\n",
    "        combined_data = combined_data[['permno', 'ticker', 'date', 'ret', 'prc', 'shrout', 'vol', 'mktcap', 'year']]\n",
    "        combined_data['date'] = pd.to_datetime(combined_data['date'])\n",
    "\n",
    "        start_date = f'{start_year}-01-01'\n",
    "        end_date = f'{end_year}-12-31'\n",
    "\n",
    "        # Query Compustat quarterly data with release dates (rdq)\n",
    "        fund_query = f\"\"\"\n",
    "            SELECT gvkey, datadate, rdq, saleq, atq, niq, lctq, epspiq\n",
    "            FROM comp.fundq\n",
    "            WHERE indfmt = 'INDL' AND datafmt = 'STD' AND popsrc = 'D' AND consol = 'C'\n",
    "            AND datadate BETWEEN '{start_date}' AND '{end_date}'\n",
    "            AND rdq IS NOT NULL\n",
    "        \"\"\"\n",
    "        fund = db.raw_sql(fund_query)\n",
    "        fund['rdq'] = pd.to_datetime(fund['rdq'])\n",
    "        fund['datadate'] = pd.to_datetime(fund['datadate'])\n",
    "\n",
    "        # Link Compustat GVKEY to CRSP PERMNO\n",
    "        link_query = \"\"\"\n",
    "            SELECT lpermno AS permno, gvkey, linkdt, linkenddt\n",
    "            FROM crsp.ccmxpf_linktable\n",
    "            WHERE linktype IN ('LU', 'LC') AND linkprim IN ('P', 'C')\n",
    "        \"\"\"\n",
    "        link = db.raw_sql(link_query)\n",
    "        fund = pd.merge(fund, link, on='gvkey', how='left')\n",
    "        fund = fund.dropna(subset=['permno'])\n",
    "\n",
    "        combined_data_sorted = combined_data.sort_values('date')\n",
    "        fund_sorted = fund.sort_values('rdq')\n",
    "        fund_sorted['permno'] = fund_sorted['permno'].astype(int)\n",
    "\n",
    "        merged = pd.merge_asof(\n",
    "            combined_data_sorted,\n",
    "            fund_sorted,\n",
    "            left_on='date',\n",
    "            right_on='rdq',\n",
    "            by='permno',\n",
    "            direction='backward'\n",
    "        )\n",
    "        merged = merged.sort_values(by='date')\n",
    "        merged = merged[['permno', 'ticker', 'date', 'ret', 'prc','vol', 'mktcap', 'gvkey', 'rdq', 'saleq', 'atq', 'niq', 'lctq', 'epspiq']]\n",
    "        merged = merged.ffill()\n",
    "\n",
    "        unique_dates = merged['date'].unique()\n",
    "        date_mapping = {date: i for i, date in enumerate(sorted(unique_dates))}\n",
    "        merged['date_mapped'] = merged['date'].map(date_mapping)\n",
    "        merged['year'] = pd.to_datetime(merged['date']).dt.year\n",
    "        final_data = merged[merged['year'] >= final_year]\n",
    "        \n",
    "        return merged, final_data\n",
    "\n",
    "    def _create_sequences(self):\n",
    "        data = self.final_data\n",
    "        lookback = self.lookback\n",
    "        unique_dates = pd.to_datetime(data['date'].unique())\n",
    "        unique_dates_sorted = np.sort(unique_dates)\n",
    "        num_features = 10  # Using: 'permno', 'ret', 'prc', 'vol', 'mktcap', 'saleq'\n",
    "\n",
    "        sequences = []\n",
    "        future_returns = []\n",
    "        masks = []\n",
    "\n",
    "        for start_idx in tqdm(range(len(unique_dates_sorted) - 2 * lookback + 1),\n",
    "                              desc=\"Creating sequences\"):\n",
    "            hist_start = unique_dates_sorted[start_idx]\n",
    "            hist_end = unique_dates_sorted[start_idx + lookback - 1]\n",
    "            future_start = unique_dates_sorted[start_idx + lookback]\n",
    "            future_end = unique_dates_sorted[start_idx + 2 * lookback - 1]\n",
    "\n",
    "            # Initialize arrays for one episode\n",
    "            batch_features = np.zeros((self.global_max_assets, lookback, num_features))\n",
    "            batch_returns = np.zeros((self.global_max_assets, lookback))\n",
    "            batch_mask = np.zeros(self.global_max_assets, dtype=bool)\n",
    "\n",
    "            for permno in self.unique_permnos:\n",
    "                idx = self.permno_to_idx[permno]\n",
    "                hist_data = data[\n",
    "                    (data['permno'] == permno) &\n",
    "                    (data['date'] >= hist_start) &\n",
    "                    (data['date'] <= hist_end)\n",
    "                ].sort_values('date')\n",
    "                future_data = data[\n",
    "                    (data['permno'] == permno) &\n",
    "                    (data['date'] >= future_start) &\n",
    "                    (data['date'] <= future_end)\n",
    "                ]['ret'].values\n",
    "\n",
    "                # Only include assets with complete data\n",
    "                if len(hist_data) == lookback and len(future_data) == lookback:\n",
    "                    features = hist_data[['permno', 'ret', 'prc', 'vol', 'mktcap', 'saleq', 'atq', 'niq', 'lctq', 'epspiq']].values\n",
    "                    batch_features[idx] = features\n",
    "                    batch_returns[idx] = future_data\n",
    "                    batch_mask[idx] = True\n",
    "\n",
    "            sequences.append(batch_features)\n",
    "            future_returns.append(batch_returns)\n",
    "            masks.append(batch_mask)\n",
    "\n",
    "        # Convert to tensors\n",
    "        sequences_tensor = torch.tensor(np.array(sequences), dtype=torch.float32)\n",
    "        future_returns_tensor = torch.tensor(np.array(future_returns), dtype=torch.float32)\n",
    "        masks_tensor = torch.tensor(np.array(masks), dtype=torch.bool)\n",
    "\n",
    "        return sequences_tensor, future_returns_tensor, masks_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.future_returns[idx], self.masks[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Model: AlphaPortfolioModel\n",
    "# -------------------------\n",
    "class AlphaPortfolioModel(nn.Module):\n",
    "    def __init__(self, num_features, lookback, d_model=32, nhead=4, num_encoder_layers=2, d_attn=16, G=5):\n",
    "        \"\"\"\n",
    "        num_features: number of asset features (e.g., 6)\n",
    "        lookback: length of the historical window (e.g., 12)\n",
    "        d_model: dimension used in the Transformer encoder\n",
    "        nhead: number of attention heads in the encoder\n",
    "        num_encoder_layers: number of Transformer encoder layers\n",
    "        d_attn: dimension used in the CAAN (query/key/value dimension)\n",
    "        G: number of assets to include in the long (and short) part of the portfolio\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.G = G\n",
    "        self.lookback = lookback\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Project raw features into the model’s embedding space\n",
    "        self.input_projection = nn.Linear(num_features, d_model)\n",
    "        \n",
    "        # SREM: Transformer Encoder to extract sequential representation\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # After the Transformer, we flatten the sequence to get the asset representation r\n",
    "        self.r_dim = lookback * d_model\n",
    "        \n",
    "        # CAAN: compute Query, Key, and Value vectors from asset representation\n",
    "        self.query_layer = nn.Linear(self.r_dim, d_attn)\n",
    "        self.key_layer = nn.Linear(self.r_dim, d_attn)\n",
    "        self.value_layer = nn.Linear(self.r_dim, d_attn)\n",
    "        \n",
    "        # Winner score generation (from the aggregated attention vector)\n",
    "        self.score_layer = nn.Linear(d_attn, 1)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x: Tensor with shape (B, A, L, F)\n",
    "           B = batch size, A = number of assets, L = lookback, F = number of features\n",
    "        mask: Boolean tensor with shape (B, A) indicating valid assets\n",
    "        \"\"\"\n",
    "        B, A, L, F = x.size()\n",
    "        # Process each asset’s historical sequence:\n",
    "        x = x.view(B * A, L, F)                # (B*A, L, F)\n",
    "        x = self.input_projection(x)           # (B*A, L, d_model)\n",
    "        x = x.transpose(0, 1)                  # (L, B*A, d_model) required by Transformer\n",
    "        encoded = self.transformer_encoder(x)   # (L, B*A, d_model)\n",
    "        encoded = encoded.transpose(0, 1)        # (B*A, L, d_model)\n",
    "        asset_repr = encoded.contiguous().view(B, A, -1)  # (B, A, L*d_model)\n",
    "        \n",
    "        # CAAN: compute query, key, and value vectors\n",
    "        Q = self.query_layer(asset_repr)  # (B, A, d_attn)\n",
    "        K = self.key_layer(asset_repr)    # (B, A, d_attn)\n",
    "        V = self.value_layer(asset_repr)    # (B, A, d_attn)\n",
    "        \n",
    "        d_attn = Q.size(-1)\n",
    "        # Compute inter-asset attention scores: (B, A, A)\n",
    "        scores = torch.bmm(Q, K.transpose(1, 2)) / math.sqrt(d_attn)\n",
    "        \n",
    "        # Mask out invalid assets in the key dimension:\n",
    "        mask_float = mask.float()            # (B, A)\n",
    "        mask_exp = mask_float.unsqueeze(1)     # (B, 1, A)\n",
    "        scores = scores + (1 - mask_exp) * (-1e9)\n",
    "        \n",
    "        # Softmax over assets j (for each asset i)\n",
    "        attn_weights = F.softmax(scores, dim=-1)  # (B, A, A)\n",
    "        # Aggregate value vectors to obtain attention vector for each asset:\n",
    "        attn_vec = torch.bmm(attn_weights, V)       # (B, A, d_attn)\n",
    "        \n",
    "        # Winner scores: use a simple FC layer followed by tanh\n",
    "        winner_scores = torch.tanh(self.score_layer(attn_vec)).squeeze(-1)  # (B, A)\n",
    "        # For invalid assets, force winner score to be very low so they are not selected\n",
    "        winner_scores = winner_scores.masked_fill(~mask, -1e9)\n",
    "        \n",
    "        # Portfolio Generation: for each batch element, choose the top G assets for long and bottom G for short positions.\n",
    "        portfolio_weights = []\n",
    "        for i in range(B):\n",
    "            scores_i = winner_scores[i]  # (A,)\n",
    "            valid_idx = mask[i].nonzero(as_tuple=False).squeeze(-1)\n",
    "            if valid_idx.numel() == 0:\n",
    "                portfolio_weights.append(torch.zeros_like(scores_i))\n",
    "                continue\n",
    "            valid_scores = scores_i[valid_idx]\n",
    "            G = self.G\n",
    "            # If not enough valid assets, adjust G:\n",
    "            G_adj = min(G, valid_scores.size(0) // 2) if valid_scores.size(0) >= 2 else 1\n",
    "\n",
    "            # For long positions: choose top G_adj highest scores.\n",
    "            sorted_long = torch.argsort(valid_scores, descending=True)\n",
    "            top_indices = valid_idx[sorted_long[:G_adj]]\n",
    "            # For short positions: choose bottom G_adj (lowest scores).\n",
    "            sorted_short = torch.argsort(valid_scores, descending=False)\n",
    "            bottom_indices = valid_idx[sorted_short[:G_adj]]\n",
    "            \n",
    "            # Compute long weights with a softmax on the top scores.\n",
    "            long_scores = scores_i[top_indices]\n",
    "            long_weights = torch.softmax(long_scores, dim=0)\n",
    "            # Compute short weights with a softmax on the negatives of the bottom scores.\n",
    "            short_scores = scores_i[bottom_indices]\n",
    "            short_weights = torch.softmax(-short_scores, dim=0)\n",
    "            \n",
    "            b = torch.zeros_like(scores_i)\n",
    "            b[top_indices] = long_weights\n",
    "            b[bottom_indices] = -short_weights  # negative weights for short positions\n",
    "            portfolio_weights.append(b)\n",
    "        portfolio_weights = torch.stack(portfolio_weights, dim=0)  # (B, A)\n",
    "        return portfolio_weights, winner_scores\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Training Loop (RL-style)\n",
    "# -------------------------\n",
    "def train_model(dataset, model, num_epochs=10, learning_rate=1e-3, device='cpu'):\n",
    "    \"\"\"\n",
    "    For each episode (one sample from the dataset), we:\n",
    "      - Feed the historical state to the model to get portfolio weights.\n",
    "      - For T trading periods (T = lookback), apply the same weights to the one‐month forward returns.\n",
    "      - Compute the episode return series and then the Sharpe ratio.\n",
    "      - Use the negative Sharpe ratio as loss and update model parameters.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    # Here we use batch_size=1 so that each batch is one episode.\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_rewards = []\n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            # Each batch is an episode: (sequences, future_returns, mask)\n",
    "            sequences, future_returns, masks = batch\n",
    "            sequences = sequences.to(device)         # shape: (1, A, L, F)\n",
    "            future_returns = future_returns.to(device) # shape: (1, A, L)\n",
    "            masks = masks.to(device)                   # shape: (1, A)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get the portfolio weights from the model (using the historical state)\n",
    "            portfolio_weights, winner_scores = model(sequences, masks)  # portfolio_weights: (1, A)\n",
    "            portfolio_weights = portfolio_weights.squeeze(0)            # (A,)\n",
    "            \n",
    "            # Simulate the episode over T periods (T = lookback, here 12 months)\n",
    "            T = future_returns.size(-1)\n",
    "            episode_returns = []\n",
    "            # For simplicity, assume the portfolio is held constant over the T periods.\n",
    "            for t in range(T):\n",
    "                # Get asset forward returns for period t\n",
    "                asset_returns_t = future_returns[0, :, t]  # (A,)\n",
    "                # Compute the portfolio return as the dot product (summing over valid assets)\n",
    "                period_return = torch.dot(portfolio_weights, asset_returns_t)\n",
    "                episode_returns.append(period_return)\n",
    "            episode_returns = torch.stack(episode_returns)  # (T,)\n",
    "            \n",
    "            # Compute Sharpe ratio (mean/std); add a small constant to std for numerical stability.\n",
    "            mean_return = torch.mean(episode_returns)\n",
    "            std_return = torch.std(episode_returns)\n",
    "            sharpe_ratio = mean_return / (std_return + 1e-6)\n",
    "            \n",
    "            # We want to maximize Sharpe ratio, so our loss is the negative Sharpe ratio.\n",
    "            loss = -sharpe_ratio\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_rewards.append(sharpe_ratio.item())\n",
    "            \n",
    "        avg_reward = np.mean(epoch_rewards)\n",
    "        logger.info(f\"Epoch {epoch+1}: Average Sharpe Ratio = {avg_reward:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Main Execution\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    start_year = 2014\n",
    "    end_year = 2020\n",
    "    final_year = 2016\n",
    "    lookback = 12\n",
    "    dataset_G = 2      # parameter used in dataset filtering\n",
    "    model_G = 5        # number of assets selected for long and short sides in the portfolio\n",
    "    num_features = 6   # as defined in our dataset\n",
    "    \n",
    "    # Initialize the dataset\n",
    "    dataset = AlphaPortfolioData(start_year=start_year, end_year=end_year,\n",
    "                                 final_year=final_year, lookback=lookback, G=dataset_G)\n",
    "    logger.info(f\"Dataset contains {len(dataset)} episodes, with {dataset.global_max_assets} assets each.\")\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = AlphaPortfolioModel(num_features=num_features, lookback=lookback,\n",
    "                                d_model=32, nhead=4, num_encoder_layers=2, d_attn=16, G=model_G)\n",
    "    \n",
    "    # Determine the device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(dataset, model, num_epochs=10, learning_rate=1e-3, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# -------------------------\n",
    "# Dataset: AlphaPortfolioData\n",
    "# -------------------------\n",
    "\n",
    "class AlphaPortfolioData(Dataset):\n",
    "    def __init__(self, start_year=2014, end_year=2020, final_year=2016, lookback=12):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "        - lookback: number of months in historical window (and also forward period length)\n",
    "        - G: parameter used when selecting top assets (here only used for filtering)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lookback = lookback\n",
    "        self.merged, self.final_data = self._load_wrds_data(start_year, end_year, final_year)\n",
    "        self.unique_permnos = sorted(self.final_data['permno'].unique())\n",
    "        self.global_max_assets = len(self.unique_permnos)\n",
    "        self.permno_to_idx = {permno: idx for idx, permno in enumerate(self.unique_permnos)}\n",
    "        self.sequences, self.future_returns, self.masks = self._create_sequences()\n",
    "\n",
    "    def _load_wrds_data(self, start_year, end_year, final_year):\n",
    "        permno_list = []\n",
    "        combined_data = pd.DataFrame()\n",
    "        for year in range(start_year, end_year+1):\n",
    "            start_date = f'{year}-01-01'\n",
    "            end_date = f'{year}-12-31'\n",
    "            crsp_query = f\"\"\"\n",
    "                SELECT a.permno, a.date, a.ret, a.prc, a.shrout, \n",
    "                    a.vol, a.cfacshr, a.altprc, a.retx\n",
    "                FROM crsp.msf AS a\n",
    "                WHERE a.date BETWEEN '{start_date}' AND '{end_date}'\n",
    "                AND a.permno IN (\n",
    "                    SELECT permno FROM crsp.msenames \n",
    "                    WHERE exchcd BETWEEN 1 AND 3  \n",
    "                        AND shrcd IN (10, 11)       \n",
    "                    )\n",
    "                \"\"\"\n",
    "            crsp_data = db.raw_sql(crsp_query)\n",
    "            query_ticker = \"\"\"\n",
    "                SELECT permno, namedt, nameenddt, ticker\n",
    "                FROM crsp.stocknames\n",
    "            \"\"\"\n",
    "            stocknames = db.raw_sql(query_ticker)\n",
    "            crsp_data = crsp_data.merge(stocknames.drop_duplicates(subset=['permno']), on='permno', how='left')\n",
    "            crsp_data = crsp_data.dropna(subset=['ticker'])\n",
    "            crsp_data['mktcap'] = (crsp_data['prc'].abs() * crsp_data['shrout'] * 1000) / 1e6  # In millions\n",
    "            crsp_data['year'] = pd.to_datetime(crsp_data['date']).dt.year\n",
    "            crsp_data = crsp_data.dropna(subset=['mktcap'])\n",
    "            top_50_permnos_by_year = crsp_data.groupby('permno')['mktcap'].agg(['max']).reset_index().sort_values(by='max', ascending=False).head(50)['permno'].unique()\n",
    "            permno_list.extend(top_50_permnos_by_year)\n",
    "            combined_data = pd.concat([combined_data, crsp_data[crsp_data['permno'].isin(permno_list)]], axis=0)\n",
    "        combined_data = combined_data[['permno', 'ticker', 'date', 'ret', 'prc', 'shrout', 'vol', 'mktcap', 'year']]\n",
    "        combined_data['date'] = pd.to_datetime(combined_data['date'])\n",
    "\n",
    "        start_date = f'{start_year}-01-01'\n",
    "        end_date = f'{end_year}-12-31'\n",
    "\n",
    "        # Query Compustat quarterly data with release dates (rdq)\n",
    "        fund_query = f\"\"\"\n",
    "            SELECT gvkey, datadate, rdq, saleq, atq, niq, lctq, epspiq\n",
    "            FROM comp.fundq\n",
    "            WHERE indfmt = 'INDL' AND datafmt = 'STD' AND popsrc = 'D' AND consol = 'C'\n",
    "            AND datadate BETWEEN '{start_date}' AND '{end_date}'\n",
    "            AND rdq IS NOT NULL\n",
    "        \"\"\"\n",
    "        fund = db.raw_sql(fund_query)\n",
    "        fund['rdq'] = pd.to_datetime(fund['rdq'])\n",
    "        fund['datadate'] = pd.to_datetime(fund['datadate'])\n",
    "\n",
    "        # Link Compustat GVKEY to CRSP PERMNO\n",
    "        link_query = \"\"\"\n",
    "            SELECT lpermno AS permno, gvkey, linkdt, linkenddt\n",
    "            FROM crsp.ccmxpf_linktable\n",
    "            WHERE linktype IN ('LU', 'LC') AND linkprim IN ('P', 'C')\n",
    "        \"\"\"\n",
    "        link = db.raw_sql(link_query)\n",
    "        fund = pd.merge(fund, link, on='gvkey', how='left')\n",
    "        fund = fund.dropna(subset=['permno'])\n",
    "\n",
    "        combined_data_sorted = combined_data.sort_values('date')\n",
    "        fund_sorted = fund.sort_values('rdq')\n",
    "        fund_sorted['permno'] = fund_sorted['permno'].astype(int)\n",
    "\n",
    "        merged = pd.merge_asof(\n",
    "            combined_data_sorted,\n",
    "            fund_sorted,\n",
    "            left_on='date',\n",
    "            right_on='rdq',\n",
    "            by='permno',\n",
    "            direction='backward'\n",
    "        )\n",
    "        merged = merged.sort_values(by='date')\n",
    "        merged = merged[['permno', 'ticker', 'date', 'ret', 'prc','vol', 'mktcap', 'gvkey', 'rdq', 'saleq', 'atq', 'niq', 'lctq', 'epspiq']]\n",
    "        merged = merged.ffill()\n",
    "\n",
    "        unique_dates = merged['date'].unique()\n",
    "        date_mapping = {date: i for i, date in enumerate(sorted(unique_dates))}\n",
    "        merged['date_mapped'] = merged['date'].map(date_mapping)\n",
    "        merged['year'] = pd.to_datetime(merged['date']).dt.year\n",
    "        final_data = merged[merged['year'] >= final_year]\n",
    "        \n",
    "        return merged, final_data\n",
    "\n",
    "    def _create_sequences(self):\n",
    "        data = self.final_data\n",
    "        lookback = self.lookback\n",
    "        unique_dates = pd.to_datetime(data['date'].unique())\n",
    "        unique_dates_sorted = np.sort(unique_dates)\n",
    "        num_features = 10  # Using: 'permno', 'ret', 'prc', 'vol', 'mktcap', 'saleq'\n",
    "\n",
    "        sequences = []\n",
    "        future_returns = []\n",
    "        masks = []\n",
    "\n",
    "        for start_idx in tqdm(range(len(unique_dates_sorted) - 2 * lookback + 1),\n",
    "                              desc=\"Creating sequences\"):\n",
    "            hist_start = unique_dates_sorted[start_idx]\n",
    "            hist_end = unique_dates_sorted[start_idx + lookback - 1]\n",
    "            future_start = unique_dates_sorted[start_idx + lookback]\n",
    "            future_end = unique_dates_sorted[start_idx + 2 * lookback - 1]\n",
    "\n",
    "            # Initialize arrays for one episode\n",
    "            batch_features = np.zeros((self.global_max_assets, lookback, num_features))\n",
    "            batch_returns = np.zeros((self.global_max_assets, lookback))\n",
    "            batch_mask = np.zeros(self.global_max_assets, dtype=bool)\n",
    "\n",
    "            for permno in self.unique_permnos:\n",
    "                idx = self.permno_to_idx[permno]\n",
    "                hist_data = data[\n",
    "                    (data['permno'] == permno) &\n",
    "                    (data['date'] >= hist_start) &\n",
    "                    (data['date'] <= hist_end)\n",
    "                ].sort_values('date')\n",
    "                future_data = data[\n",
    "                    (data['permno'] == permno) &\n",
    "                    (data['date'] >= future_start) &\n",
    "                    (data['date'] <= future_end)\n",
    "                ]['ret'].values\n",
    "\n",
    "                # Only include assets with complete data\n",
    "                if len(hist_data) == lookback and len(future_data) == lookback:\n",
    "                    features = hist_data[['permno', 'ret', 'prc', 'vol', 'mktcap', 'saleq', 'atq', 'niq', 'lctq', 'epspiq']].values\n",
    "                    batch_features[idx] = features\n",
    "                    batch_returns[idx] = future_data\n",
    "                    batch_mask[idx] = True\n",
    "\n",
    "            sequences.append(batch_features)\n",
    "            future_returns.append(batch_returns)\n",
    "            masks.append(batch_mask)\n",
    "\n",
    "        # Convert to tensors\n",
    "        sequences_tensor = torch.tensor(np.array(sequences), dtype=torch.float32)\n",
    "        future_returns_tensor = torch.tensor(np.array(future_returns), dtype=torch.float32)\n",
    "        masks_tensor = torch.tensor(np.array(masks), dtype=torch.bool)\n",
    "\n",
    "        return sequences_tensor, future_returns_tensor, masks_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.future_returns[idx], self.masks[idx]\n",
    "# -------------------------\n",
    "# Model: AlphaPortfolioModel\n",
    "# -------------------------\n",
    "class AlphaPortfolioModel(nn.Module):\n",
    "    def __init__(self, num_features, lookback, d_model=32, nhead=4, num_encoder_layers=2, d_attn=16, G=5):\n",
    "        \"\"\"\n",
    "        - num_features: number of input features (e.g. 6)\n",
    "        - lookback: length of historical window (e.g. 12)\n",
    "        - d_model: embedding dimension for Transformer\n",
    "        - nhead: number of attention heads\n",
    "        - num_encoder_layers: number of Transformer layers\n",
    "        - d_attn: dimension for query/key/value in CAAN\n",
    "        - G: number of assets to include on each side (long and short)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.G = G\n",
    "        self.lookback = lookback\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Project raw features into embedding space.\n",
    "        self.input_projection = nn.Linear(num_features, d_model)\n",
    "        \n",
    "        # SREM: Transformer Encoder for sequence representation.\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        \n",
    "        # After encoding, we flatten the sequence to obtain an asset representation r.\n",
    "        self.r_dim = lookback * d_model\n",
    "        \n",
    "        # CAAN: linear layers to compute Query, Key, Value from asset representation.\n",
    "        self.query_layer = nn.Linear(self.r_dim, d_attn)\n",
    "        self.key_layer = nn.Linear(self.r_dim, d_attn)\n",
    "        self.value_layer = nn.Linear(self.r_dim, d_attn)\n",
    "        \n",
    "        # Winner score: project aggregated attention vector into a score.\n",
    "        self.score_layer = nn.Linear(d_attn, 1)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (B, A, L, F)\n",
    "           B = batch size (number of episodes)\n",
    "           A = number of assets\n",
    "           L = lookback length (months)\n",
    "           F = number of features\n",
    "        mask: Boolean Tensor of shape (B, A) indicating valid assets.\n",
    "        \"\"\"\n",
    "        B, A, L, num_features = x.size()\n",
    "        # Flatten the assets and process each asset’s historical sequence.\n",
    "        x = x.view(B * A, L, num_features)                # (B*A, L, F)\n",
    "        x = self.input_projection(x)           # (B*A, L, d_model)\n",
    "        x = x.transpose(0, 1)                  # (L, B*A, d_model) for Transformer\n",
    "        encoded = self.transformer_encoder(x)   # (L, B*A, d_model)\n",
    "        encoded = encoded.transpose(0, 1)        # (B*A, L, d_model)\n",
    "        asset_repr = encoded.contiguous().view(B, A, -1)  # (B, A, L*d_model)\n",
    "        \n",
    "        # CAAN: compute query, key, and value vectors.\n",
    "        Q = self.query_layer(asset_repr)  # (B, A, d_attn)\n",
    "        K = self.key_layer(asset_repr)    # (B, A, d_attn)\n",
    "        V = self.value_layer(asset_repr)  # (B, A, d_attn)\n",
    "        \n",
    "        d_attn = Q.size(-1)\n",
    "        # Compute inter-asset attention scores: (B, A, A)\n",
    "        scores = torch.bmm(Q, K.transpose(1, 2)) / math.sqrt(d_attn)\n",
    "        \n",
    "        # Mask out invalid assets (set scores for invalid keys very low).\n",
    "        mask_float = mask.float()            # (B, A)\n",
    "        mask_exp = mask_float.unsqueeze(1)     # (B, 1, A)\n",
    "        scores = scores + (1 - mask_exp) * (-1e9)\n",
    "        \n",
    "        # Softmax over assets (for each asset i, normalize over j).\n",
    "        attn_weights = F.softmax(scores, dim=-1)  # (B, A, A)\n",
    "        # Aggregate value vectors: attention vector for each asset.\n",
    "        attn_vec = torch.bmm(attn_weights, V)       # (B, A, d_attn)\n",
    "        \n",
    "        # Winner scores: use an FC layer and tanh.\n",
    "        winner_scores = torch.tanh(self.score_layer(attn_vec)).squeeze(-1)  # (B, A)\n",
    "        # For invalid assets, force winner score to be very low.\n",
    "        winner_scores = winner_scores.masked_fill(~mask, -1e9)\n",
    "        \n",
    "        # Portfolio Generation:\n",
    "        # For each batch element, select top G for long positions and bottom G for short positions.\n",
    "        portfolio_weights = []\n",
    "        for i in range(B):\n",
    "            scores_i = winner_scores[i]  # (A,)\n",
    "            valid_idx = mask[i].nonzero(as_tuple=False).squeeze(-1)\n",
    "            if valid_idx.numel() == 0:\n",
    "                portfolio_weights.append(torch.zeros_like(scores_i))\n",
    "                continue\n",
    "            valid_scores = scores_i[valid_idx]\n",
    "            G = self.G\n",
    "            # Adjust G if not enough valid assets.\n",
    "            G_adj = min(G, valid_scores.size(0) // 2) if valid_scores.size(0) >= 2 else 1\n",
    "\n",
    "            # For long positions: top G_adj highest scores.\n",
    "            sorted_long = torch.argsort(valid_scores, descending=True)\n",
    "            top_indices = valid_idx[sorted_long[:G_adj]]\n",
    "            # For short positions: bottom G_adj lowest scores.\n",
    "            sorted_short = torch.argsort(valid_scores, descending=False)\n",
    "            bottom_indices = valid_idx[sorted_short[:G_adj]]\n",
    "            \n",
    "            # Compute long weights (softmax over top scores).\n",
    "            long_scores = scores_i[top_indices]\n",
    "            long_weights = torch.softmax(long_scores, dim=0)\n",
    "            # Compute short weights (softmax over negative bottom scores).\n",
    "            short_scores = scores_i[bottom_indices]\n",
    "            short_weights = torch.softmax(-short_scores, dim=0)\n",
    "            \n",
    "            b = torch.zeros_like(scores_i)\n",
    "            b[top_indices] = long_weights\n",
    "            b[bottom_indices] = -short_weights  # negative for short positions\n",
    "            portfolio_weights.append(b)\n",
    "        portfolio_weights = torch.stack(portfolio_weights, dim=0)  # (B, A)\n",
    "        return portfolio_weights, winner_scores\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Training Loop (RL-style)\n",
    "# -------------------------\n",
    "def train_model(dataset, model, num_epochs=10, learning_rate=1e-4, device='cpu', batch_size=4):\n",
    "    \"\"\"\n",
    "    For each episode (a sample from the dataset), we:\n",
    "      - Feed the historical state (sequences) to the model to get portfolio weights.\n",
    "      - Apply these weights to the next 12 months of forward returns (for each asset).\n",
    "      - Compute a 12-month return series for each episode.\n",
    "      - Calculate the Sharpe ratio (mean/std) per episode.\n",
    "      - Use the negative mean Sharpe ratio across episodes as the loss.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_sharpes = []\n",
    "        for sequences, future_returns, masks in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            # sequences: (B, A, L, F); future_returns: (B, A, T); masks: (B, A)\n",
    "            sequences = sequences.to(device)\n",
    "            future_returns = future_returns.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get portfolio weights for each episode.\n",
    "            portfolio_weights, winner_scores = model(sequences, masks)  # portfolio_weights: (B, A)\n",
    "            \n",
    "            # Apply portfolio weights to each forward period.\n",
    "            # Expand portfolio_weights to (B, A, 1) and multiply elementwise with future_returns (B, A, T).\n",
    "            # Sum over assets to get period returns for each episode.\n",
    "            period_returns = (portfolio_weights.unsqueeze(-1) * future_returns).sum(dim=1)  # (B, T)\n",
    "            \n",
    "            # Compute Sharpe ratio per episode.\n",
    "            mean_returns = period_returns.mean(dim=1)  # (B,)\n",
    "            std_returns = period_returns.std(dim=1)      # (B,)\n",
    "            sharpe_ratios = mean_returns / (std_returns + 1e-6)  # (B,)\n",
    "            \n",
    "            # Our loss is the negative average Sharpe ratio.\n",
    "            loss = -sharpe_ratios.mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_sharpes.extend(sharpe_ratios.detach().cpu().numpy().tolist())\n",
    "            \n",
    "        avg_sharpe = np.mean(epoch_sharpes)\n",
    "        logger.info(f\"Epoch {epoch+1}: Average Sharpe Ratio = {avg_sharpe:.4f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Main Execution\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    start_year = 2014\n",
    "    end_year = 2020\n",
    "    final_year = 2016\n",
    "    lookback = 12\n",
    "    dataset_G = 2      # parameter used in dataset filtering\n",
    "    model_G = 10        # number of assets selected for long and short in portfolio generation\n",
    "    num_features = 10   # as defined in our dataset\n",
    "    batch_size = 1     # adjust as needed\n",
    "    \n",
    "    # Initialize the dataset\n",
    "    dataset = AlphaPortfolioData(start_year=start_year, end_year=end_year,\n",
    "                                 final_year=final_year, lookback=lookback)\n",
    "    logger.info(f\"Dataset contains {len(dataset)} episodes, with {dataset.global_max_assets} assets each.\")\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = AlphaPortfolioModel(num_features=num_features, lookback=lookback,\n",
    "                                d_model=256, nhead=8, num_encoder_layers=8, d_attn=8, G=model_G)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    logger.info(f\"Using device: {device}\")\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(dataset, model, num_epochs=20, learning_rate=1e-4, device=device, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PART 3 HOPEFULLY EVERYTHING IS IN ORDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import wrds\n",
    "import logging\n",
    "\n",
    "# -------------------------\n",
    "# Logging Setup\n",
    "# -------------------------\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# -------------------------\n",
    "# Establish WRDS Connection\n",
    "# -------------------------\n",
    "db = wrds.Connection()  # Ensure your WRDS credentials/environment are set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Dataset: AlphaPortfolioData\n",
    "# -------------------------\n",
    "class AlphaPortfolioData(Dataset):\n",
    "    def __init__(self, start_year=2014, end_year=2020, final_year=2016, lookback=12, T = 12):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "        \n",
    "        For each asset, we load historical data from CRSP and Compustat via WRDS.\n",
    "        \n",
    "        We then build sequential episodes for RL. Each episode has T time steps\n",
    "        (we set T = lookback, e.g. 12). At each time step t:\n",
    "          - The state is the historical window of length 'lookback' for all assets.\n",
    "            (Shape: [num_assets, lookback, num_features])\n",
    "          - The forward (one‐month) return for each asset is extracted.\n",
    "            (Shape: [num_assets])\n",
    "          - A mask indicates whether the asset has complete data.\n",
    "        \n",
    "        Overall, each episode is composed of:\n",
    "          - state_seq: (T, num_assets, lookback, num_features)\n",
    "          - fwd_seq: (T, num_assets)\n",
    "          - mask_seq: (T, num_assets)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.lookback = lookback\n",
    "        self.T = T\n",
    "        self.merged, self.final_data = self._load_wrds_data(start_year, end_year, final_year)\n",
    "        self.unique_permnos = sorted(self.final_data['permno'].unique())\n",
    "        self.global_max_assets = len(self.unique_permnos)\n",
    "        self.permno_to_idx = {permno: idx for idx, permno in enumerate(self.unique_permnos)}\n",
    "        self.sequences, self.future_returns, self.masks = self._create_sequences()\n",
    "        logger.info(f\"Dataset initialized: {len(self.sequences)} episodes created.\")\n",
    "        if len(self.sequences) > 0:\n",
    "            logger.info(f\"Example episode state shape: {self.sequences[0].shape} \"\n",
    "                        f\"(T, num_assets, lookback, num_features)\")\n",
    "            logger.info(f\"Example episode future returns shape: {self.future_returns[0].shape} \"\n",
    "                        f\"(T, num_assets)\")\n",
    "            logger.info(f\"Example episode mask shape: {self.masks[0].shape} \"\n",
    "                        f\"(T, num_assets)\")\n",
    "\n",
    "    def _load_wrds_data(self, start_year, end_year, final_year):\n",
    "        \"\"\"\n",
    "        Loads CRSP and Compustat data via WRDS.\n",
    "        Returns:\n",
    "          merged: the full merged DataFrame (all dates)\n",
    "          final_data: DataFrame filtered to years >= final_year\n",
    "        \"\"\"\n",
    "        permno_list = []\n",
    "        combined_data = pd.DataFrame()\n",
    "        for year in range(start_year, end_year+1):\n",
    "            start_date = f'{year}-01-01'\n",
    "            end_date = f'{year}-12-31'\n",
    "            crsp_query = f\"\"\"\n",
    "                SELECT a.permno, a.date, a.ret, a.prc, a.shrout, \n",
    "                       a.vol, a.cfacshr, a.altprc, a.retx\n",
    "                FROM crsp.msf AS a\n",
    "                WHERE a.date BETWEEN '{start_date}' AND '{end_date}'\n",
    "                  AND a.permno IN (\n",
    "                      SELECT permno FROM crsp.msenames \n",
    "                      WHERE exchcd BETWEEN 1 AND 3  \n",
    "                        AND shrcd IN (10, 11)\n",
    "                  )\n",
    "                \"\"\"\n",
    "            crsp_data = db.raw_sql(crsp_query)\n",
    "            query_ticker = \"\"\"\n",
    "                SELECT permno, namedt, nameenddt, ticker\n",
    "                FROM crsp.stocknames\n",
    "            \"\"\"\n",
    "            stocknames = db.raw_sql(query_ticker)\n",
    "            crsp_data = crsp_data.merge(stocknames.drop_duplicates(subset=['permno']), on='permno', how='left')\n",
    "            crsp_data = crsp_data.dropna(subset=['ticker'])\n",
    "            crsp_data['mktcap'] = (crsp_data['prc'].abs() * crsp_data['shrout'] * 1000) / 1e6  # In millions\n",
    "            crsp_data['year'] = pd.to_datetime(crsp_data['date']).dt.year\n",
    "            crsp_data = crsp_data.dropna(subset=['mktcap'])\n",
    "            top_50_permnos_by_year = crsp_data.groupby('permno')['mktcap'].agg(['max']).reset_index()\\\n",
    "                                     .sort_values(by='max', ascending=False).head(50)['permno'].unique()\n",
    "            permno_list.extend(top_50_permnos_by_year)\n",
    "            combined_data = pd.concat([combined_data, crsp_data[crsp_data['permno'].isin(permno_list)]], axis=0)\n",
    "        combined_data = combined_data[['permno', 'ticker', 'date', 'ret', 'prc', 'shrout', 'vol', 'mktcap', 'year']]\n",
    "        combined_data['date'] = pd.to_datetime(combined_data['date'])\n",
    "\n",
    "        start_date = f'{start_year}-01-01'\n",
    "        end_date = f'{end_year}-12-31'\n",
    "        # Query Compustat quarterly data with release dates (rdq)\n",
    "        fund_query = f\"\"\"\n",
    "            SELECT gvkey, datadate, rdq, saleq\n",
    "            FROM comp.fundq\n",
    "            WHERE indfmt = 'INDL' AND datafmt = 'STD' AND popsrc = 'D' AND consol = 'C'\n",
    "              AND datadate BETWEEN '{start_date}' AND '{end_date}'\n",
    "              AND rdq IS NOT NULL\n",
    "            \"\"\"\n",
    "        fund = db.raw_sql(fund_query)\n",
    "        fund['rdq'] = pd.to_datetime(fund['rdq'])\n",
    "        fund['datadate'] = pd.to_datetime(fund['datadate'])\n",
    "        # Link Compustat GVKEY to CRSP PERMNO\n",
    "        link_query = \"\"\"\n",
    "            SELECT lpermno AS permno, gvkey, linkdt, linkenddt\n",
    "            FROM crsp.ccmxpf_linktable\n",
    "            WHERE linktype IN ('LU', 'LC') AND linkprim IN ('P', 'C')\n",
    "            \"\"\"\n",
    "        link = db.raw_sql(link_query)\n",
    "        fund = pd.merge(fund, link, on='gvkey', how='left')\n",
    "        fund = fund.dropna(subset=['permno'])\n",
    "        combined_data_sorted = combined_data.sort_values('date')\n",
    "        fund_sorted = fund.sort_values('rdq')\n",
    "        fund_sorted['permno'] = fund_sorted['permno'].astype(int)\n",
    "        merged = pd.merge_asof(\n",
    "            combined_data_sorted,\n",
    "            fund_sorted,\n",
    "            left_on='date',\n",
    "            right_on='rdq',\n",
    "            by='permno',\n",
    "            direction='backward'\n",
    "        )\n",
    "        merged = merged.sort_values(by='date')\n",
    "        merged = merged[['permno', 'ticker', 'date', 'ret', 'prc','vol', 'mktcap', \n",
    "                         'gvkey', 'rdq', 'saleq']]\n",
    "        merged = merged.ffill()\n",
    "        unique_dates = merged['date'].unique()\n",
    "        date_mapping = {date: i for i, date in enumerate(sorted(unique_dates))}\n",
    "        merged['date_mapped'] = merged['date'].map(date_mapping)\n",
    "        merged['year'] = pd.to_datetime(merged['date']).dt.year\n",
    "        final_data = merged[merged['year'] >= final_year]\n",
    "        logger.info(f\"Data loaded: merged shape {merged.shape}, final_data shape {final_data.shape}\")\n",
    "        return merged, final_data\n",
    "\n",
    "    def _create_sequences(self):\n",
    "        \"\"\"\n",
    "        Creates sequential episodes for RL.\n",
    "        \n",
    "        For each episode, we use a sliding window over the sorted unique dates.\n",
    "        Let T = lookback (i.e. we rebalance for lookback months sequentially).\n",
    "        For an episode starting at index i, for each time step t (0 <= t < T):\n",
    "          - The state (for rebalancing time t) is the data from date index i+t to i+t+lookback-1.\n",
    "          - The one-month forward return is taken from date index i+t+lookback.\n",
    "        \n",
    "        This yields:\n",
    "          - state_seq: (T, num_assets, lookback, num_features)\n",
    "          - fwd_seq:   (T, num_assets)\n",
    "          - mask_seq:  (T, num_assets)\n",
    "        \"\"\"\n",
    "        data = self.final_data\n",
    "        lookback = self.lookback\n",
    "        T = self.T  # number of rebalancing steps per episode\n",
    "        unique_dates = pd.to_datetime(data['date'].unique())\n",
    "        unique_dates_sorted = np.sort(unique_dates)\n",
    "        num_features = 6  # Using: 'permno', 'ret', 'prc', 'vol', 'mktcap', 'saleq', 'atq', 'niq', 'lctq', 'epspiq'\n",
    "        \n",
    "        episodes_states = []\n",
    "        episodes_fwd = []\n",
    "        episodes_masks = []\n",
    "        num_episodes = len(unique_dates_sorted) - (2 * lookback) + 1\n",
    "        logger.info(f\"Creating {num_episodes} sequential episodes (T = {T} time steps each).\")\n",
    "        for start_idx in tqdm(range(num_episodes), desc=\"Creating sequential episodes\"):\n",
    "            episode_states = []  # will have shape (T, global_max_assets, lookback, num_features)\n",
    "            episode_fwd = []     # will have shape (T, global_max_assets)\n",
    "            episode_masks = []   # will have shape (T, global_max_assets)\n",
    "            for t in range(T):\n",
    "                state_start = start_idx + t\n",
    "                state_end = state_start + lookback\n",
    "                fwd_index = state_end  # forward return index for this time step\n",
    "                step_states = np.zeros((self.global_max_assets, lookback, num_features))\n",
    "                step_fwd = np.zeros((self.global_max_assets,))\n",
    "                step_mask = np.zeros((self.global_max_assets,), dtype=bool)\n",
    "                for permno in self.unique_permnos:\n",
    "                    idx = self.permno_to_idx[permno]\n",
    "                    hist_data = data[\n",
    "                        (data['permno'] == permno) &\n",
    "                        (data['date'] >= unique_dates_sorted[state_start]) &\n",
    "                        (data['date'] < unique_dates_sorted[state_end])\n",
    "                    ].sort_values('date')\n",
    "                    fwd_data = data[\n",
    "                        (data['permno'] == permno) &\n",
    "                        (data['date'] == unique_dates_sorted[fwd_index])\n",
    "                    ]\n",
    "                    if len(hist_data) == lookback and len(fwd_data) == 1:\n",
    "                        # Extract the features: 'permno', 'ret', 'prc', 'vol', 'mktcap', 'saleq', 'atq', 'niq', 'lctq', 'epspiq'\n",
    "                        features = hist_data[['permno', 'ret', 'prc', 'vol', 'mktcap', \n",
    "                                               'saleq']].values\n",
    "                        step_states[idx] = features\n",
    "                        step_fwd[idx] = fwd_data['ret'].values[0]\n",
    "                        step_mask[idx] = True\n",
    "                episode_states.append(step_states)\n",
    "                episode_fwd.append(step_fwd)\n",
    "                episode_masks.append(step_mask)\n",
    "            # Convert the lists for this episode into arrays.\n",
    "            episode_states = np.array(episode_states)   # shape: (T, global_max_assets, lookback, num_features)\n",
    "            episode_fwd = np.array(episode_fwd)           # shape: (T, global_max_assets)\n",
    "            episode_masks = np.array(episode_masks)       # shape: (T, global_max_assets)\n",
    "            episodes_states.append(episode_states)\n",
    "            episodes_fwd.append(episode_fwd)\n",
    "            episodes_masks.append(episode_masks)\n",
    "        # Convert the episodes lists to tensors.\n",
    "        sequences_tensor = torch.tensor(np.array(episodes_states), dtype=torch.float32)\n",
    "        future_returns_tensor = torch.tensor(np.array(episodes_fwd), dtype=torch.float32)\n",
    "        masks_tensor = torch.tensor(np.array(episodes_masks), dtype=torch.bool)\n",
    "        logger.info(f\"Created sequences tensor shape: {sequences_tensor.shape}\")\n",
    "        logger.info(f\"Created future_returns tensor shape: {future_returns_tensor.shape}\")\n",
    "        logger.info(f\"Created masks tensor shape: {masks_tensor.shape}\")\n",
    "        return sequences_tensor, future_returns_tensor, masks_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Returns a tuple:\n",
    "        #   (state_seq, fwd_seq, mask_seq)\n",
    "        # where:\n",
    "        #   state_seq: (T, num_assets, lookback, num_features)\n",
    "        #   fwd_seq:   (T, num_assets)\n",
    "        #   mask_seq:  (T, num_assets)\n",
    "        return self.sequences[idx], self.future_returns[idx], self.masks[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Model: AlphaPortfolioModel (SREM + CAAN + Portfolio Generator)\n",
    "# -------------------------\n",
    "class AlphaPortfolioModel(nn.Module):\n",
    "    def __init__(self, num_features, lookback, d_model=32, nhead=4, num_encoder_layers=2, d_attn=16, G=5):\n",
    "        \"\"\"\n",
    "        The model processes an asset's historical state (shape: (num_assets, lookback, num_features))\n",
    "        and produces a portfolio weight vector (one weight per asset).\n",
    "        It uses:\n",
    "          - An input projection to embed each time step.\n",
    "          - A Transformer encoder (SREM) to capture temporal dependencies.\n",
    "          - A CAAN module to compute inter-asset relationships.\n",
    "          - A portfolio generator that selects top and bottom G assets.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.G = G\n",
    "        self.lookback = lookback\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Log the initialization.\n",
    "        logger.info(f\"Initializing AlphaPortfolioModel with num_features={num_features}, lookback={lookback}, d_model={d_model}, nhead={nhead}, num_encoder_layers={num_encoder_layers}, d_attn={d_attn}, G={G}\")\n",
    "        \n",
    "        # Project raw features into embedding space.\n",
    "        self.input_projection = nn.Linear(num_features, d_model)\n",
    "        logger.info(f\"Input projection layer: {self.input_projection}\")\n",
    "\n",
    "        # SREM: Transformer Encoder for sequence representation.\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        logger.info(\"Transformer encoder initialized.\")\n",
    "\n",
    "        # After encoding, we flatten the sequence to obtain an asset representation r.\n",
    "        self.r_dim = lookback * d_model\n",
    "        logger.info(f\"Asset representation dimension (r_dim): {self.r_dim}\")\n",
    "\n",
    "        # CAAN: linear layers to compute Query, Key, Value from asset representation.\n",
    "        self.query_layer = nn.Linear(self.r_dim, d_attn)\n",
    "        self.key_layer = nn.Linear(self.r_dim, d_attn)\n",
    "        self.value_layer = nn.Linear(self.r_dim, d_attn)\n",
    "        logger.info(\"CAAN layers (query, key, value) initialized.\")\n",
    "\n",
    "        # Winner score: project aggregated attention vector into a score.\n",
    "        self.score_layer = nn.Linear(d_attn, 1)\n",
    "        logger.info(\"Score layer for winner scores initialized.\")\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "          x: Tensor of shape (B, num_assets, lookback, num_features)\n",
    "          mask: Tensor of shape (B, num_assets)\n",
    "        Returns:\n",
    "          portfolio_weights: Tensor of shape (B, num_assets)\n",
    "          winner_scores: Tensor of shape (B, num_assets)\n",
    "        Detailed logging is provided at each step.\n",
    "        \"\"\"\n",
    "        logger.info(f\"[Model] Input x shape: {x.shape}\")\n",
    "        B, A, L, feat_dim = x.size()\n",
    "        # Flatten the assets dimension to process each asset's sequence independently.\n",
    "        x = x.view(B * A, L, feat_dim)  # (B*A, L, feat_dim)\n",
    "        logger.info(f\"[Model] After flattening: {x.shape}\")\n",
    "        \n",
    "        # Project raw features into embeddings.\n",
    "        x = self.input_projection(x)    # (B*A, L, d_model)\n",
    "        logger.info(f\"[Model] After input projection: {x.shape}\")\n",
    "        \n",
    "        # Transpose for the Transformer: required shape (L, B*A, d_model)\n",
    "        x = x.transpose(0, 1)           # (L, B*A, d_model)\n",
    "        logger.info(f\"[Model] After transpose for Transformer: {x.shape}\")\n",
    "        \n",
    "        # Pass through the Transformer encoder.\n",
    "        encoded = self.transformer_encoder(x)  # (L, B*A, d_model)\n",
    "        logger.info(f\"[Model] After Transformer encoder: {encoded.shape}\")\n",
    "        \n",
    "        # Transpose back to (B*A, L, d_model)\n",
    "        encoded = encoded.transpose(0, 1)  # (B*A, L, d_model)\n",
    "        logger.info(f\"[Model] After transpose back: {encoded.shape}\")\n",
    "        \n",
    "        # Flatten the time dimension: each asset gets a single representation vector.\n",
    "        asset_repr = encoded.contiguous().view(B, A, -1)  # (B, A, L*d_model)\n",
    "        logger.info(f\"[Model] Asset representation shape: {asset_repr.shape}\")\n",
    "        \n",
    "        # CAAN: compute query, key, and value vectors.\n",
    "        Q = self.query_layer(asset_repr)  # (B, A, d_attn)\n",
    "        K = self.key_layer(asset_repr)      # (B, A, d_attn)\n",
    "        V = self.value_layer(asset_repr)    # (B, A, d_attn)\n",
    "        logger.info(f\"[Model] Query shape: {Q.shape}, Key shape: {K.shape}, Value shape: {V.shape}\")\n",
    "        \n",
    "        d_attn = Q.size(-1)\n",
    "        # Compute inter-asset attention scores.\n",
    "        scores = torch.bmm(Q, K.transpose(1, 2)) / math.sqrt(d_attn)  # (B, A, A)\n",
    "        logger.info(f\"[Model] Attention scores shape: {scores.shape}\")\n",
    "        \n",
    "        # Mask out invalid assets: for assets with mask=False, set scores to a large negative number.\n",
    "        mask_float = mask.float()           # (B, A)\n",
    "        mask_exp = mask_float.unsqueeze(1)    # (B, 1, A)\n",
    "        scores = scores + (1 - mask_exp) * (-1e9)\n",
    "        logger.info(\"[Model] Applied mask to attention scores.\")\n",
    "        \n",
    "        # Softmax over assets (for each asset i, normalize over j).\n",
    "        attn_weights = F.softmax(scores, dim=-1)  # (B, A, A)\n",
    "        logger.info(f\"[Model] Attention weights shape: {attn_weights.shape}\")\n",
    "        \n",
    "        # Aggregate value vectors: compute the attention vector for each asset.\n",
    "        attn_vec = torch.bmm(attn_weights, V)  # (B, A, d_attn)\n",
    "        logger.info(f\"[Model] Aggregated attention vector shape: {attn_vec.shape}\")\n",
    "        \n",
    "        # Compute winner scores using a fully connected layer and tanh activation.\n",
    "        winner_scores = torch.tanh(self.score_layer(attn_vec)).squeeze(-1)  # (B, A)\n",
    "        logger.info(f\"[Model] Winner scores shape (pre-mask): {winner_scores.shape}\")\n",
    "        # For invalid assets, set the winner score to a very low value.\n",
    "        winner_scores = winner_scores.masked_fill(~mask, -1e9)\n",
    "        logger.info(\"[Model] Applied mask to winner scores.\")\n",
    "        \n",
    "        # -------------------------\n",
    "        # Portfolio Generation:\n",
    "        # For each batch element, select top G for long positions and bottom G for short positions.\n",
    "        # -------------------------\n",
    "        portfolio_weights = []\n",
    "        for i in range(B):\n",
    "            scores_i = winner_scores[i]  # (A,)\n",
    "            valid_idx = mask[i].nonzero(as_tuple=False).squeeze(-1)\n",
    "            logger.info(f\"[Model] Batch {i}: valid asset indices: {valid_idx}\")\n",
    "            if valid_idx.numel() == 0:\n",
    "                portfolio_weights.append(torch.zeros_like(scores_i))\n",
    "                continue\n",
    "            valid_scores = scores_i[valid_idx]\n",
    "            G = self.G\n",
    "            # Adjust G if not enough valid assets.\n",
    "            G_adj = min(G, valid_scores.size(0) // 2) if valid_scores.size(0) >= 2 else 1\n",
    "            logger.info(f\"[Model] Batch {i}: G_adj = {G_adj}\")\n",
    "\n",
    "            # For long positions: top G_adj highest scores.\n",
    "            sorted_long = torch.argsort(valid_scores, descending=True)\n",
    "            top_indices = valid_idx[sorted_long[:G_adj]]\n",
    "            logger.info(f\"[Model] Batch {i}: top_indices for long positions: {top_indices}\")\n",
    "            # For short positions: bottom G_adj lowest scores.\n",
    "            sorted_short = torch.argsort(valid_scores, descending=False)\n",
    "            bottom_indices = valid_idx[sorted_short[:G_adj]]\n",
    "            logger.info(f\"[Model] Batch {i}: bottom_indices for short positions: {bottom_indices}\")\n",
    "            \n",
    "            # Compute long weights (softmax over top scores).\n",
    "            long_scores = scores_i[top_indices]\n",
    "            long_weights = torch.softmax(long_scores, dim=0)\n",
    "            logger.info(f\"[Model] Batch {i}: long_weights: {long_weights}\")\n",
    "            # Compute short weights (softmax over negative bottom scores).\n",
    "            short_scores = scores_i[bottom_indices]\n",
    "            short_weights = torch.softmax(-short_scores, dim=0)\n",
    "            logger.info(f\"[Model] Batch {i}: short_weights: {short_weights}\")\n",
    "            \n",
    "            b = torch.zeros_like(scores_i)\n",
    "            b[top_indices] = long_weights\n",
    "            b[bottom_indices] = -short_weights  # negative for short positions\n",
    "            logger.info(f\"[Model] Batch {i}: portfolio weights: {b}\")\n",
    "            portfolio_weights.append(b)\n",
    "        portfolio_weights = torch.stack(portfolio_weights, dim=0)  # (B, A)\n",
    "        logger.info(f\"[Model] Final portfolio_weights shape: {portfolio_weights.shape}\")\n",
    "        return portfolio_weights, winner_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Training Loop (RL-style Sequential Rebalancing)\n",
    "# -------------------------\n",
    "def train_model_sequential(dataset, model, num_epochs=10, learning_rate=1e-4, device='cpu', batch_size=1):\n",
    "    \"\"\"\n",
    "    Each episode consists of T sequential rebalancing steps.\n",
    "    For each step t (0 <= t < T):\n",
    "      - Get the state (of shape: (num_assets, lookback, num_features))\n",
    "      - Compute portfolio weights for that month.\n",
    "      - Get the one-month forward returns (of shape: (num_assets,)) for that month.\n",
    "      - Compute the portfolio return (dot product) for that month.\n",
    "    After T steps, compute the Sharpe ratio of the T monthly returns as the delayed reward.\n",
    "    Detailed logging is included at every step.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    model.train()\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        logger.info(f\"--- Starting Epoch {epoch+1}/{num_epochs} ---\")\n",
    "        epoch_sharpes = []\n",
    "        for episode_idx, (state_seq, fwd_seq, mask_seq) in enumerate(tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n",
    "            # state_seq: (B, T, A, lookback, num_features)\n",
    "            # fwd_seq: (B, T, A)\n",
    "            # mask_seq: (B, T, A)\n",
    "            logger.info(f\"[Episode {episode_idx}] state_seq shape: {state_seq.shape}, fwd_seq shape: {fwd_seq.shape}, mask_seq shape: {mask_seq.shape}\")\n",
    "            \n",
    "            # We'll process each episode sequentially (time steps t=0 to T-1)\n",
    "            B, T, A, L, F = state_seq.size()\n",
    "            monthly_returns = []\n",
    "            for t in range(T):\n",
    "                state_t = state_seq[:, t, :, :, :]   # shape: (B, A, L, F)\n",
    "                fwd_t = fwd_seq[:, t, :]              # shape: (B, A)\n",
    "                mask_t = mask_seq[:, t, :]            # shape: (B, A)\n",
    "                logger.info(f\"[Episode {episode_idx}][Time {t}] state_t shape: {state_t.shape}, fwd_t shape: {fwd_t.shape}\")\n",
    "                \n",
    "                # Compute portfolio weights for this time step.\n",
    "                portfolio_weights, winner_scores = model(state_t, mask_t)  # portfolio_weights: (B, A)\n",
    "                logger.info(f\"[Episode {episode_idx}][Time {t}] portfolio_weights: {portfolio_weights}\")\n",
    "                logger.info(f\"[Episode {episode_idx}][Time {t}] winner_scores: {winner_scores}\")\n",
    "                \n",
    "                # Compute portfolio return for time t.\n",
    "                # Expand portfolio_weights to (B, A, 1) so that we can multiply elementwise with fwd_t (B, A)\n",
    "                # Since fwd_t is a scalar per asset for that month, do elementwise multiplication and sum over assets.\n",
    "                period_return = (portfolio_weights * fwd_t).sum(dim=1)  # (B,)\n",
    "                logger.info(f\"[Episode {episode_idx}][Time {t}] period_return: {period_return}\")\n",
    "                monthly_returns.append(period_return.squeeze(0))  # assuming B=1; adjust accordingly\n",
    "            \n",
    "            # After T steps, stack monthly returns to get a tensor of shape (T,)\n",
    "            monthly_returns = torch.stack(monthly_returns)  # (T,)\n",
    "            logger.info(f\"[Episode {episode_idx}] Monthly returns: {monthly_returns}\")\n",
    "            \n",
    "            # Compute Sharpe ratio for the episode.\n",
    "            mean_return = monthly_returns.mean()\n",
    "            std_return = monthly_returns.std()\n",
    "            sharpe_ratio = mean_return / (std_return + 1e-6)\n",
    "            logger.info(f\"[Episode {episode_idx}] Episode Sharpe Ratio: {sharpe_ratio}\")\n",
    "            \n",
    "            loss = -sharpe_ratio\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_sharpes.append(sharpe_ratio.item())\n",
    "        \n",
    "        avg_sharpe = np.mean(epoch_sharpes)\n",
    "        logger.info(f\"Epoch {epoch+1}: Average Sharpe Ratio = {avg_sharpe:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINAL EXECUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-11 15:02:32,719 - INFO - Data loaded: merged shape (2661, 12), final_data shape (2067, 12)\n",
      "2025-02-11 15:02:32,729 - INFO - Creating 13 sequential episodes (T = 12 time steps each).\n",
      "Creating sequential episodes: 100%|██████████| 13/13 [00:06<00:00,  1.88it/s]\n",
      "2025-02-11 15:02:39,692 - INFO - Created sequences tensor shape: torch.Size([13, 12, 62, 12, 6])\n",
      "2025-02-11 15:02:39,693 - INFO - Created future_returns tensor shape: torch.Size([13, 12, 62])\n",
      "2025-02-11 15:02:39,693 - INFO - Created masks tensor shape: torch.Size([13, 12, 62])\n",
      "2025-02-11 15:02:39,694 - INFO - Dataset initialized: 13 episodes created.\n",
      "2025-02-11 15:02:39,697 - INFO - Example episode state shape: torch.Size([12, 62, 12, 6]) (T, num_assets, lookback, num_features)\n",
      "2025-02-11 15:02:39,698 - INFO - Example episode future returns shape: torch.Size([12, 62]) (T, num_assets)\n",
      "2025-02-11 15:02:39,698 - INFO - Example episode mask shape: torch.Size([12, 62]) (T, num_assets)\n",
      "2025-02-11 15:02:39,699 - INFO - Dataset contains 13 episodes, each with 12 time steps, 62 assets.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------------\n",
    "# Main Execution\n",
    "# -------------------------\n",
    "\n",
    "lookback = 12\n",
    "start_year = 2015\n",
    "final_year = 2016\n",
    "end_year = 2018\n",
    "T = 12  # number of rebalancing steps (months) per episode\n",
    "model_G = 3        # number of assets selected for long and short in portfolio generation\n",
    "batch_size = 1     # we process one episode at a time for clarity in logging\n",
    "num_epochs = 3     # set to a small number for demonstration\n",
    "\n",
    "# Initialize the dataset.\n",
    "dataset = AlphaPortfolioData(start_year=start_year, end_year=end_year, final_year=final_year, lookback=lookback, T=T)\n",
    "logger.info(f\"Dataset contains {dataset.sequences.shape[0]} episodes, each with {dataset.sequences.shape[1]} time steps, {dataset.sequences.shape[2]} assets.\")\n",
    "\n",
    "num_features = dataset.sequences.shape[-1]\n",
    "\n",
    "# # Initialize the model.\n",
    "# model = AlphaPortfolioModel(num_features=num_features, lookback=lookback,\n",
    "#                             d_model=16, nhead=2, num_encoder_layers=1, d_attn=8, G=model_G)\n",
    "\n",
    "# # Determine device.\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# # Train the model using sequential rebalancing.\n",
    "# train_model_sequential(dataset, model, num_epochs=num_epochs, learning_rate=1e-4, device=device, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.final_data[dataset.final_data['ticker'] == 'NVDA'].to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 12\n",
    "start_year = 2014\n",
    "final_year = 2016\n",
    "end_year = 2020\n",
    "T = 12  # number of rebalancing steps (months) per episode\n",
    "\n",
    "dataset = AlphaPortfolioData(start_year=start_year, end_year=end_year, final_year=final_year, lookback=lookback, T=T)\n",
    "logger.info(f\"Dataset contains {dataset.sequences.shape[0]} episodes, each with {dataset.sequences.shape[1]} time steps, {dataset.sequences.shape[2]} assets.\")\n",
    "\n",
    "num_features = dataset.sequences.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_G = 5        # number of assets selected for long and short in portfolio generation\n",
    "batch_size = 1     # we process one episode at a time for clarity in logging\n",
    "num_epochs = 3     # set to a small number for demonstration\n",
    "\n",
    "model = AlphaPortfolioModel(num_features=num_features, lookback=lookback,\n",
    "                            d_model=32, nhead=4, num_encoder_layers=2, d_attn=16, G=model_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logger.info(f\"Using device: {device}\")\n",
    "\n",
    "# Train the model using sequential rebalancing.\n",
    "train_model_sequential(dataset, model, num_epochs=num_epochs, learning_rate=1e-4, device=device, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
